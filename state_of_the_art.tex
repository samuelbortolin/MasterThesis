\chapter{State of the Art}
\label{cha:soa}
\vspace{0.4 cm}

In this chapter, the current state of the art is analyzed in the context of electricity data representation and time series forecasting methods.
In the first section, a brief introduction to the proposed standards for electricity data representation is presented.
Subsequently, various technologies presented in the literature for time series forecasting are discussed.
In particular, several implementations and use cases are presented.
Additionally, an extensive analysis is conducted on two prominent subjects in the research community: Transformers and Automated Machine Learning (AutoML).
These topics are thoroughly explored in dedicated subsections.
Furthermore, the three use cases of interest, electricity demand forecasting, consumption baseline forecasting, and electricity production forecasting, are treated in more detail in dedicated sections.
At the end of this chapter, it will be clear the context around which the proposed system is developed.


\section{Electricity data representation}
\label{sec:data}
\vspace{0.2 cm}

In this section, a discussion of electricity data representation and proposed standards is presented.
Data issues and frameworks for handling this kind of data are also discussed.

One of the most popular standards for energy data is the Green Button Data\footnote{ \url{https://www.greenbuttondata.org/} }, which is an industry initiative in response to the 2012 White House call-to-action to provide customers easy and secure access to their energy usage information in a both consumer-friendly and computer-friendly format.
The data supported is not limited to electricity but may also include natural gas, and water usage.
Customers using this service are able to securely and easily download their own detailed energy usage in a standard format.
This possibility allows customers to choose to upload their own energy data to a third-party application or automate the secure transfer to authorized third parties, based on affirmative customer consent and control.
It is a very powerful initiative in the U.S. that enables a variety of new services.
Services like UtilityAPI are compatible with the Green Button standard providing support for APIs and XML schemas\footnote{ \url{https://utilityapi.com/docs/greenbutton} }.

\cite{Nguyen2019} provided a case study and explained the lessons learned through the roll-out of Green Button electricity, natural gas, and water data-access initiative, in order to make readily available energy and water consumption data for consumers and third-party companies, that can assist customers while ensuring security and privacy of their data.
This paper presented a case study using the Green Button standard and the steps taken to ensure data security and privacy while enabling access to those consumption data by the consumer and third parties.
Data security and privacy were achieved through the use of the Green Button standard and subsequent implementation by the Green Button Alliance of a compliance-testing program.
Considerations and solutions were needed for data in transit, data at rest, and the authorization mechanisms for allowing unregulated third-party companies to interface directly with utilities on behalf of the consumer while ensuring the consumer maintains complete control of what is to be shared and the ability to revoke that sharing at any time.

In \cite{CHEN201798},  Chen et al. studied the quality of electricity consumption data in a smart grid environment.
They defined and classified which are common data quality issues that may arise in this field.
In particular, the data quality issues related to electricity consumption are classified into three types: noisy data, incomplete data, and outlier data.
These three types of data quality issues are discussed.
The paper introduced the causes of electricity consumption outlier data and provided a review of the possible detection methods.
This is a relevant study since most industrial studies in this field use real-world data that presents these issues.

\cite{8577770} presented a big-data-based framework for dealing with electricity consumption behavior.
It conducted an analysis of the current state-of-the-art methodologies for the extraction of electro-information and it presented the drawbacks of existing modeling strategies for power consumption behavior.
The paper proposed a way of integrating multiple-dimensional information into electricity consumption data, such as weather, holiday, and economic level.
It dealt also with issues such as anonymization, abnormal detections, and meter failures.
The final objective was to conduct an in-depth study for pattern identification, relational analysis, and understanding of the possible actions to perform based on electricity usage.


\section{Time series forecasting}
\label{sec:timeseries}
\vspace{0.2 cm}

In this section, a brief introduction to forecasting competitions, the use of cross-validation for the evaluation of time series forecasting methods, and techniques for time series forecasting is presented.
Time series forecasting is a classic and well-studied topic.
The classical approaches, which are based on statistical methods such as Auto-Regressive Integrated Moving Average (ARIMA), have been joined in recent years by standard Machine Learning (ML) methods and recently also by Deep Learning (DL) methods with the use of neural networks and transformers.

A brief review of forecasting competitions was presented in \cite{HYNDMAN20207}.
These competitions were proposed to promote the development of new solutions and novel techniques in this field.
Over time, these competitions have gained significant attention, resulting in a growing interest in time series forecasting and ultimately fostering the development of fascinating and impactful solutions.
The first and most influential forecasting competitions were, and currently are, the M-competitions\footnote{ \url{https://en.wikipedia.org/wiki/Makridakis_Competitions} }.
These competitions promoted the application of the most recent statistical approaches such as ARIMA, ML approaches such as Support Vector Regression (SVR), and DL approaches such as Long Short-Term Memory (LSTM) networks developed over time to be applied to the forecasting field.
Issues like the statistical significance of the results, cheating using part of the test sets for training, and reproducibility of the results were addressed over the competitions.
Also, other competitions were held such as Sante Fe competitions, the KDD cup, Neural network competitions, Kaggle time series competitions, and Global energy forecasting competitions.

\cite{SPILIOTIS202037} presented an interesting discussion on whether forecasting competition data are representative of reality.
This is a very important point since the performance of new forecasting methods is typically evaluated by relying on data from past forecasting competitions.
However, due to their many limitations, these datasets might not be indicative.
Since obtaining a complete picture of the real world is impossible in practice, the paper proposed to use the M4 competition data as an indication of the real world.
This is reasonable since this data set is composed of many series from the business world.
The properties of this dataset were compared with past datasets, showing that many popular benchmarks may deviate from reality.
The main differences observed were referred to the abnormality of the data, in fact, data from the real world presents relatively more skewed series with outliers, as well as their limited randomness\slash trend.

In \cite{BERGMEIR2012192}, Bergmeir and Ben√≠tez presented a study on the use of cross-validation for time series forecasting methods evaluation.
They aimed to combine the evaluation of traditional forecasting procedures, on the one hand, and the evaluation of ML techniques on the other hand.
In fact, in traditional forecasting, a part from the end of each time series is reserved for testing, and the rest is used for training.
Instead, when evaluating ML and other regression methods, often cross-validation is used in the evaluation process without paying much attention to the fact that there are theoretical problems concerning temporal evolutionary effects and dependencies within the data that invalidate the fundamental assumptions of cross-validation, such as to have i.i.d. (independent and identically distributed) data.
They suggested that the use of a blocked form of cross-validation for time series evaluation should be the standard procedure, thus using all available information and circumventing the theoretical problems.
They also affirmed that the use of cross-validation techniques, together with adequate control for stationarity, led to a more robust model selection.

In \cite{Cerqueira2020}, Cerqueira et al. studied the application of performance estimation methods to time series forecasting.
They stated that the dependency among observations in time series raises some caveats about the most appropriate way to estimate models' performance since cross-validation cannot be applied to this type of data.
Results of a comparative study of different performance estimation methods showed noticeable differences among them.
In particular, their empirical experiments suggested that blocked cross-validation can be applied to stationary time series.
However, when the time series are non-stationary, the most accurate performance estimation methods were out-of-sample methods and in particular the holdout approach repeated in multiple testing periods showed the most accurate estimates.

Subsequently, relevant studies within the context of time series forecasting are outlined, beginning with classical approaches and culminating in contemporary state-of-the-art approaches.

\cite{DEGOOIJER2006443} is a paper published in 2006 and it reviewed the research into time series forecasting made from 1982 to 2005.
Many relevant methods were presented such as exponential smoothing, ARIMA, state space models, structural models, Kalman filter, regime-switching models, functional-coefficient models, neural networks, and many others also involving the combination of approaches.
There were also a lot of relevant studies that presented theoretical concepts such as Seasonality, Forecast evaluation and accuracy measures, and Prediction intervals and densities.
The authors concluded by saying that enormous progress has been made in many areas, but that there were a large number of topics that need further development such as multivariate time series forecasting, forecasting methods based on nonlinear models, model selection procedures, robust statistical methods, and improved forecast intervals.

In \cite{Nesreen2010}, Nesreen et al. presented a large-scale comparison study for the major ML models adopted for time series forecasting.
The models considered were Multi-Layer Perceptron (MLP), Bayesian neural networks, radial basis functions, Generalized Regression Neural Networks (GRNN), K-Nearest Neighbor (KNN) regression, Classification and Regression Trees (CART), SVR, and Gaussian processes.
The study revealed significant differences between the different methods and proclaimed as the best two methods on the monthly M3 time series competition data the MLP and the Gaussian process regression.

\cite{BENTAIEB20127067} proposed a review and a comparison of different strategies for multi-step ahead time series forecasting based on the NN5 forecasting competition.
They also considered the effects of deseasonalization, input variable selection, and combination on the strategies.
From experimental results, they figured out that:
(i) Multiple-Output strategies were the best-performing approaches,
(ii) deseasonalization led to uniformly improved forecast accuracy,
and (iii) input selection was more effective when performed in conjunction with deseasonalization.

In \cite{TEALAB2018334}, Tealab studied the advances in time series forecasting models using Artificial Neural Network (ANN) methodologies.
He took into consideration the papers published from 2006 to 2016.
From the analysis of the papers, he concluded that, although many studies presented the application of neural network models, few of them proposed new neural network models for forecasting.
He found out that these many studies had a similar hybrid methodology that consisted in adjusting a linear time series model, and subsequently using the residuals as the input variables of an ANN model.

\cite{Athiyarath2020} proposed a comparative study and analysis of various time series forecasting techniques such as linear regression model, ARIMA, LSTM, and many others.
In particular, it explored their limitations and utility for different types of time series data across different domains.

\cite{SEZER2020106181} provided a comprehensive literature review of DL studies with a focus on financial time series forecasting implementation.
They categorized the studies according to their intended forecasting implementation areas and grouped them based on their DL model choices, such as Convolutional Neural Networks (CNNs), Deep Belief Networks (DBNs), and LSTM.

In \cite{HEWAMALAGE2021388}, Hewamalage et al. presented an empirical study resulting in an open-source software framework for time series forecasting using Recurrent Neural Network (RNN) architectures.
They concluded that RNN architectures were capable of directly modeling seasonality when the time series presented homogeneous seasonal patterns.
If this is not the case, they recommend a deseasonalization step for achieving better results.
They also provided some comparisons against exponential smoothing and ARIMA demonstrating that RNN models even were not perfect, they were good alternatives.

In \cite{Lim2021}, Lim and Zohren analyzed the main architecture used in both one-step-ahead and multi-horizon time series forecasting.
They described how temporal information is incorporated into predictions by each of the models, such as CNNs, RNNs, and networks with attention mechanisms.
They also highlighted the recent developments in hybrid DL models, which combine statistical models with neural network components to improve performance.

\cite{Masini2023} presented the recent ML advances for time series forecasting.
They started by analyzing the linear methods, paying more attention to penalized regressions and ensembles of models.
They continued presenting nonlinear methods, including tree-based methods, such as Random Forest and Gradient-Boosted Decision Trees (GBDT), and shallow and deep neural networks, in their feed-forward and recurrent versions.
Finally, they also consider ensemble and hybrid models by combining different alternatives.

These reviews have aided in understanding the most commonly utilized methods in time series forecasting and identifying potentially effective solutions for general use cases.
Furthermore, specific studies that present distinct methodologies are carefully examined and analyzed.

\cite{ZHANG2003159} presented a hybrid model combining ARIMA and ANN models.
This was an innovative study of 2003 and was done to take advantage of both strengths of the ARIMA and the ANN models in linear and nonlinear modeling respectively.
The experimental results indicated that the combination was an effective way to improve the forecasting accuracy achieved by both models used separately.

\cite{CAO2003321} proposed to use an approach including multiple Support Vector Machines (SVMs) for time series forecasting.
The multiple SVMs that best fit the regions partitioned by a self-organizing feature map were constructed by finding the most appropriate kernel function and the optimal parameters of the different SVMs.
Simulation results showed that the proposed multiple SVMs approach achieved significant improvement in the generalization performance in comparison with the single SVMs models.
In addition, it was shown that the multiple SVMs were also able to converge faster and use fewer support vectors.

\cite{6210391} attempted to develop an automatic ANN modeling scheme for time series forecasting.
This scheme was based on the GRNN, a special type of neural network.
By taking advantage of several GRNN properties (i.e., a single design parameter and fast learning) and by incorporating several design strategies (e.g., fusing multiple GRNNs), they were able to make the proposed modeling scheme to be effective for modeling large-scale business time series.

\cite{Oliveira2015} described a new type of ensemble improving the predictive performance with respect to existing ensembles for time series forecasting.
In particular, they proposed a new form of diversity generation that explores some specific properties of time series prediction tasks.
Their experiments confirmed that the proposed method for generating diversity was able to improve the performance of the equivalent ensembles with standard diversity generation procedures.

In the study conducted by Sean and Letham \cite{Sean2017}, they introduced Prophet, a modular regression model that offers interpretable parameters.
One of the notable advantages of Prophet is its flexibility in parameter adjustment based on domain knowledge, allowing for intuitive customization based on the characteristics of the time series being analyzed.
Additionally, the researchers also outlined a crucial component that measures and tracks forecast accuracy.
This feature serves to flag forecasts that should be manually reviewed, allowing incremental improvements in the forecasting process.
This capability is vital as it helps in identifying when adjustments are required for the existing model or when an entirely different model may be more suitable for accurate predictions.

In \cite{Borovykh2017}, Borovykh et al. presented a method for conditional time series forecasting based on an adaptation of the recent deep convolutional WaveNet architecture.
The proposed method took advantage of dilated convolutions for considering a broad history horizon when forecasting.
The conditioning process in the study involved the application of multiple parallel convolutional filters to individual time series.
This approach facilitated efficient data processing and allowed the exploitation of the correlation structures present among the multivariate time series.
Through experimental evaluations, it was demonstrated that the proposed network was particularly suitable for regression-type problems.
Notably, the network exhibited the capability to effectively learn dependencies within and between the time series, even in cases where extensive historical time series data was not available.
Moreover, the performance of the network surpassed that of linear and recurrent models, highlighting its superior predictive capabilities.

\cite{DEOSANTOSJUNIOR201972} proposed a hybrid system that searches for a suitable function to combine the forecasts of linear and nonlinear models.
The proposed system performed linear and nonlinear modeling of the time series and a data-driven combination that searches for the most suitable function, between linear and nonlinear formalisms, and also the number of models that maximizes the performance of the combination.
As a linear model, the ARIMA model is used and as nonlinear models, MLP and SVR were used.
Experimental results showed that the proposed hybrid system attains superior performance when compared to both single and hybrid models previously reported in the literature.

In \cite{SHEN2020302}, Shen et al. proposed SeriesNet, which is a novel time series forecasting model able to learn features of time series data in different interval lengths.
It is composed of a LSTM network and a dilated causal convolution network.
The fact that the proposed model could learn multi-range and multi-level features from time series data led to a higher predictive accuracy compared to those models using fixed time intervals.

\cite{SMYL202075} presented the winning submission of the M4 forecasting competition.
The winning approach employed a dynamic computational graph neural network system, which combined a standard exponential smoothing model with advanced LSTM networks within a unified framework.
This novel hybrid and hierarchical forecasting method demonstrated superior performance compared to all other models submitted in the competition.
The successful integration of these techniques resulted in enhanced forecasting capabilities, showcasing the effectiveness of the proposed approach in surpassing existing methodologies.

In the context of building better pricing modeling and forecasting frameworks to meet difficulties, \cite{en16031371} proposed to combine seasonal and trend decomposition utilizing LOESS (locally estimated scatterplot smoothing) and Prophet methodologies to perform a more accurate and resilient time series analysis of Italian electricity spot prices.
The proposed method could assist in enhancing projections and providing a better understanding of the variables driving the data.
Experimental results showed that the combination of approaches improved the forecast accuracy and lowered the Mean Absolute Percentage Error (MAPE) performance metric by 18\% compared to the Prophet baseline model.


\vspace{0.1 cm}
\subsection{Attention and transformers}
\label{sec:transformers}
\vspace{0.1 cm}

In this subsection, an overview of attention-based and transformer approaches is presented, with a focus on time series forecasting applications.

\cite{NIU202148} provided an overview of the state-of-the-art attention models proposed.
They classified existing attention models according to the following criteria: the softness of attention, forms of input features, input representation, and output representation.
They also summarized the network architectures used in conjunction with the attention mechanism and described some applications where attention mechanisms are used to improve performance.
Finally, they discussed the interpretability that attention mechanisms provide to the DL models, but also the challenges and prospects of attention models.

\cite{9586824} presented a review of the developed attention mechanism with a focus on the neural machine translation task.
They covered the most adopted attention models and their variants, such as self-attention, soft attention, hard attention, local attention, global attention, additive attention, and multiplicative attention.

\cite{9892274} analyzed that attention mechanisms have raised significant interest in the research community since they promised relevant improvements in the performance of neural network architectures.
In particular, since self-attention was proposed, it has been widely used in transformer-like architectures and has led to significant breakthroughs in many applications.
In the work, Pedro and Oliveira performed an objective comparison of several different attention mechanisms for the classification of samples in the Skin Cancer MNIST dataset.
The results showed that attention modules only sometimes improved the performance of CNN architectures, but also that this improvement was not consistent in different settings.
On the other hand, the results obtained with self-attention mechanisms showed consistent and significant improvements, leading to the best results even in architectures with a reduced number of parameters.

The study presented in \cite{LI2019104785} introduced an evolutionary attention learning approach for enhancing LSTM models in multivariate time series prediction tasks.
The researchers proposed a competitive random search method inspired by evolutionary computation to optimize the configuration of parameters within the attention layer.
Experimental results demonstrated that the proposed model achieved competitive prediction performance when compared to other baseline methods.
This highlights the effectiveness of the evolutionary attention learning approach in improving the predictive capabilities of LSTM models for multivariate time series forecasting.

In \cite{Shih2019}, Shih et al. analyzed that the standard attention mechanisms in multivariate time series forecasting reviewed just the information at each previous time step from which to select relevant information to generate the outputs.
For this reason, these mechanisms were unable to effectively capture temporal patterns across multiple time steps.
In the study, they proposed a set of filters designed to extract time-invariant temporal patterns.
Additionally, they developed a novel attention mechanism that not only selects relevant time series but also utilizes frequency domain information for multivariate time series forecasting.
Finally, they applied the proposed approach to many real-world tasks demonstrating that it was able to achieve state-of-the-art performance in most of them.

In \cite{DU2020269}, Du et al. proposed a novel temporal attention encoder-decoder model to successfully deal with multivariate time series forecasting.
They developed an end-to-end DL structure that combined the classical encoder-decoder learning structure with a temporal attention mechanism.
This integrated approach enabled the simultaneous learning of long-term temporal dependency and hidden non-linear correlation features within multivariate temporal data.
Experimental results on five multivariate time series datasets showed that the proposed model had the best forecasting performance compared with baseline models, such as SVR, RNN, CNN, LSTM, and Gated Recurrent Unit (GRU).

\cite{HEIDARI2020626} aimed to predict the energy use of solar-assisted water heating systems using a novel ML approach.
They proposed to use a LSTM network enhanced by an attention mechanism and the decomposition of input data into sub-layers.
They compared the performance of the proposed approach with a feed-forward neural network, a LSTM network, and an Attention-based LSTM neural network.
The experimental results showed that the proposed model outperformed conventional models in this task.

Liu et al. analyzed that the current attention-based recurrent neural networks can effectively represent and learn the dynamic spatiotemporal relationships between exogenous series and target series, but they only perform well in one-step time prediction and short-term time prediction.
In \cite{LIU2020113082}, they proposed dual-stage two-phase-based RNN (DSTP-RNN) for long-term time series prediction.
The DSTP-based structure was designed to enhance spatial correlations between exogenous series.
The first phase of the model generated violent but decentralized response weights, while the second phase led to stationary and concentrated response weights.
Multiple head attention was then employed on the target series to amplify the long-term dependencies.
Experimental results showcased the effectiveness of the proposed model across a range of applications, outperforming nine baseline methods on four datasets from the domains of energy, finance, environment, and medicine.
These findings suggest that the DSTP-RNN model holds promise for developing accurate and robust prediction systems in diverse fields.

In \cite{Vaswani2017}, Vaswani et al. proposed the Transformer architecture, based solely on attention mechanisms and fully connected feed-forward networks, with the addition of layer normalization and residual connections.
Experimental results on machine translation tasks showed that this groundbreaking model was superior in quality achieving better results than existing methods being more parallelizable and requiring significantly less time to train.
Moreover, they also showed that the Transformer is able to generalize to other tasks like English constituency parsing.

In \cite{Wu2020}, Wu et al. presented a new approach to time series forecasting by developing a novel method that employs Transformer-based models to forecast time series data.
The approach leveraged self-attention mechanisms to effectively capture and understand complex patterns and dynamics from time series data.
They created a generic framework that can be applied to univariate and multivariate time series data, as well as time series embeddings.
The influenza-like illness (ILI) forecasting was used as a case study.
They showed the effectiveness of the proposed approach and that the produced forecasting results are favorably comparable to the state-of-the-art.

\cite{Zhou2020} discussed the several severe issues of Transformer architecture that prevent it from being directly applicable to long sequence time series forecasting (LSTF), including quadratic time complexity, high memory usage, and the limitation of the encoder-decoder architecture.
To address these issues, Zhou et al. designed an efficient transformer-based model for LSTF, named Informer.
It had some distinctive characteristics, such as a ProbSparse self-attention mechanism, which achieves O(L log L) in time complexity and memory usage, the self-attention distilling highlights dominating attention by halving cascading layer input, the generative style decoder predicts the long time series sequences in one forward operation rather than a step-by-step way.
Extensive experiments on four large-scale datasets demonstrated that Informer significantly outperformed existing methods and provided a new solution to the LSTF problem.

\cite{Grigsby2021} analyzed the state-of-the-art models for multivariate time series forecasting.
They discussed that sequence-to-sequence models rely on attention between timesteps, which allows for temporal learning but fails to consider distinct spatial relationships between variables.
In contrast, graph neural network methods explicitly model variable relationships, however, often rely on predefined graphs and perform separate spatial and temporal updates without establishing direct connections between each variable at every timestep.
The study addressed the presented problems by using a Transformer and translating the multivariate forecasting task into a spatiotemporal sequence formulation so that each Transformer input represented the value of a single variable at a given time.
Using this formulation, they were able to let Long-Range Transformers jointly learn interactions between space, time, and value information.
The proposed method, called Spacetimeformer, achieved competitive results on benchmarks of different domains while learning fully-connected spatiotemporal relationships purely from data.

In \cite{LIM20211748}, Lim et al. introduced the Temporal Fusion Transformer (TFT), a novel attention-based architecture able to combine high-performance multi-horizon forecasting with interpretable insights into temporal dynamics.
The presented TFT relied on recurrent layers for local processing and on interpretable self-attention layers for long-term dependencies.
It was able to select relevant features and suppress unnecessary components through a series of gating layers.
Experimental results on a variety of real-world datasets demonstrated significant performance improvements over existing benchmarks and they also highlighted some practical interpretability use cases enabled by the TFT architecture.
TFT architecture was a breakthrough in time series forecasting and achieved state-of-the-art performance in several tasks.
Hereafter, some studies using this architecture are presented.

In \cite{9745215}, the TFT was applied to forecast the trajectory of future vital signs based on time-varying measurements of past vital signs.
This application holds significant importance since the deterioration of a patient's condition is usually preceded by several hours of abnormal physiology as indicated by the patient's vital signs.
The model was developed using the Songklanagarind critical care dataset, which includes vital sign measurements from 140 patients.
Experimental results showed that TFT was able to capture the temporal dynamics of vital signs and can potentially be used to detect irregular patterns in vital sign time series.
This suggests that TFT has the potential to assist in the early detection of abnormal physiological patterns and contribute to improved patient care and monitoring in critical care settings.

In \cite{ZHANG2022329}, a TFT was adopted to predict freeway speed with prediction horizons from 5 to 150 minutes.
A traffic speed data set was employed to train and evaluate the TFT prediction model, showcasing the advantages offered by this approach.
The TFT prediction performance was compared with several classic traffic speed prediction methods, and the results revealed that the TFT outperformed the other classic models when the prediction horizon is longer than 30 minutes.
Moreover, the TFT is also more stable when the prediction horizon is 60 minutes or longer.
These findings highlight the effectiveness of TFT in accurately predicting freeway speed and its superiority over traditional methods, especially being stable also for longer prediction horizons.

\cite{WU2022123990} used a novel forecasting approach for interpretable wind speed prediction by incorporating variational mode decomposition (VMD), a TFT model, and an evolutionary algorithm.
In the proposed approach, VMD was employed to break down the raw wind speed sequence into a set of intrinsic mode functions.
Adaptive differential evolution was then used for optimizing several parameters of a TFT allowing it to achieve satisfactory forecasting performance.
Empirical studies using real-world wind speed data sets demonstrated that the proposed model outperformed other comparable models in nearly all performance metrics.
Moreover, TFT allowed gaining information about the importance ranking of the decomposed wind speed sub-sequences, meteorological data, and attention analysis of different step lengths.
These findings underscore the effectiveness and interpretability of the proposed approach in wind speed prediction tasks.


\vspace{0.1 cm}
\subsection{Automated machine learning}
\label{sec:automl}
\vspace{0.1 cm}

In this subsection, an overview of the developed approaches in the AutoML field is presented, with a focus on time series forecasting applications.

\cite{Elshawi2019} emphasized the necessity of automating the process of building good ML models, mainly due to the exponential growth in data volume, which exceeds the capacity of human data scientists.
In this study, Elshawi et al. presented a comprehensive survey that focused on the Combined Algorithm Selection and Hyper-parameter tuning (CASH) problem in the ML domain.
In addition, they highlighted the importance of automating other steps within the ML pipeline, ranging from data understanding to model deployment.
They provided an overview of the state-of-the-art efforts, tools, and frameworks that have been proposed to address these challenges.
Finally, the study discussed various research directions and open challenges that need to be tackled to realize the vision and goals of AutoML, including scalability, optimization techniques, time budget management, and data preparation.

\cite{9579526} observed that data scientists cannot tackle the growing number of challenging tasks due to a lack of expertise and experience across all task domains.
To help address this issue, the study provided a survey of ongoing research in the field of Meta-Learning and AutoML.
It covered AutoML tools such as TransmogrifAI, Auto-Sklearn, AutoGluon, and NNI.
It also summarized possible uses of Meta-Learning for DL, few-shot learning, and automating the ML process.

In \cite{8995391}, Truong et al. conducted a thorough investigation into the current landscape of AutoML tools designed to automate repetitive tasks within ML pipelines.
These tasks include data pre-processing, feature engineering, model selection, hyperparameter optimization, and prediction result analysis.
performed multiple evaluations of these tools using diverse datasets to assess their performance and compare their respective strengths and weaknesses.
The study revealed that while most AutoML tools achieved reasonable results in terms of performance across a wide range of datasets, no single tool managed to outperform all others consistently in all tasks.
Among the tools evaluated, H2O AutoML, Auto-Keras, and Auto-Sklearn demonstrated better performance than Ludwig, Darwin, TPOT, and Auto-ml across various evaluations and benchmarks.

\cite{9033810} reviewed the various AutoML, hyperparameter tuning, and meta-learning approaches available in the literature and pointed out that most of them are neither properly documented nor very clear due to the differences in the approaches.
The strengths and drawbacks of the various approaches and their reviews in terms of algorithms supported, features, and implementations are explored.

\cite{HE2021106622} presented a comprehensive review of the state-of-the-art in AutoML.
He et al. introduced AutoML methods covering data preparation, feature engineering, hyperparameter optimization, and Neural Architecture Search (NAS) with a focus on automating the DL pipeline.
They summarized the representative NAS algorithms' performance on the CIFAR-10 and ImageNet datasets and discussed relevant topics of the NAS methods such as one\slash two-stage NAS, one-shot NAS, joint hyperparameter and architecture optimization, and resource-aware NAS.
Finally, they discussed some open problems related to the existing AutoML methods for future research such as flexible search space, areas exploration, interpretability, reproducibility, and robustness.

In \cite{Karmaker2021}, Karmaker et al. proposed a classification system for AutoML systems, using a tier schematic to distinguish systems based on their level of autonomy.
They described what an end-to-end ML pipeline actually looks like and analyzed which subtasks have been automated and which are done manually.
In fact, most AutoML systems still require human involvement in some steps, including understanding the attributes of domain-specific data, defining prediction problems, creating a suitable training dataset, and selecting a promising ML technique.
These steps often require a prolonged back-and-forth that makes the process inefficient and keeps AutoML systems from being truly automatic.
They introduced the proposed level-based taxonomy for AutoML systems and defined each level according to the scope of automation support provided.
Finally, they discussed the challenges that stand in the way of automating the whole end-to-end ML pipeline.

In \cite{Chen2021}, Chen et al. described AutoML as a bi-level optimization problem, where one problem is nested within another to search for the optimum in the search space.
They reviewed the current developments of AutoML presenting the state-of-the-art techniques and frameworks in terms of three main categories:
automated feature engineering (AutoFE),
automated model and hyperparameter tuning (AutoMHT),
and Automated Deep Learning (AutoDL).
They concluded by presenting the open challenges of AutoML such as the lack of authoritative benchmarks, efficiency, design of search spaces, and interpretability.

In 2015, Feurer et al. stated that to be effective in practice, ML systems need to automatically choose a good algorithm and feature preprocessing steps for a new dataset at hand, and also set their respective hyperparameters.
Starting from existing work on efficient Bayesian optimization methods, in \cite{Feurer2015} they presented a robust new AutoML system based on the scikit-learn framework: Auto-Sklearn.
Auto-Sklearn incorporated 15 classifiers, 14 feature preprocessing methods, and 4 data preprocessing methods, resulting in a structured hypothesis space with 110 hyperparameters.
One key improvement of Auto-Sklearn was its ability to leverage past performance on similar datasets, taking into account this information during the optimization process.
Furthermore, the system constructed ensembles from the evaluated models.
Experimental results on a wide range of more than 100 diverse datasets demonstrated that Auto-Sklearn substantially outperformed the previous state of the art in AutoML.

In \cite{Jin2019}, Jin et al. proposed a novel framework for efficient NAS enabling Bayesian optimization to guide the network morphism, which essentially keeps the functionality of a neural network while changing its neural architecture.
The framework, called Auto-Keras, employed a neural network kernel and a tree-structured optimization algorithm to facilitate efficient exploration of the search space.
Through extensive experiments conducted on real-world benchmark datasets, they demonstrated the superior performance of the developed framework over the state-of-the-art NAS methods.

In \cite{8955514}, Dyrmishi et al. presented a methodology and a framework for using Meta-Learning techniques to develop new methods that serve as effective decision support for the AutoML process.
Meta-Learning allows learning from previous experience gained during applying various learning algorithms on different types of data and helps reduce the time needed to learn new tasks.
In particular, they used Meta-Learning techniques to answer several crucial questions for the AutoML process such as which classifiers are expected to be the best performing on a given dataset, whether it is possible to predict the training time of a classifier, and which classifiers are worth investing a larger portion of the time budget to improve their performance by tuning them.
In the Meta-Learning process, they used 200 datasets with different characteristics and 30 classifiers from Weka and Scikit-learn libraries.
As a result, this method allowed Meta-Models to be obtained in a fully automated way.

\cite{Gijsbers2019} introduced an open-source benchmark framework for comparing different AutoML systems following best practices and avoiding common mistakes.
The framework is extensible both in terms of AutoML frameworks and tasks.
They used the framework to conduct a thorough comparison of 4 AutoML systems (Auto-WEKA, Auto-Sklearn, TPOT, and H2O AutoML) across 39 datasets.
They analyzed the results and highlighted the need for further AutoML research.
In fact, on some datasets, none of the frameworks outperformed a Random Forest within 4 hours, and high-dimensional or highly multi-class problems were often challenging for AutoML frameworks.

In \cite{computers10010011}, Vaccaro et al. reviewed some ML models and methods proposed in the literature to analyze their strengths and weaknesses.
Then, they proposed their use, alone or in combination with other approaches, to provide possible valid AutoML solutions.
They analyzed these solutions from a theoretical point of view and evaluated them empirically on three Atari games.
The objective of the study was to identify what could be some promising ways to create effective AutoML frameworks able to replace the human expert as much as possible and thereby make the process of applying ML approaches to typical problems of specific domains easier.
The research provided valuable insights into potential directions for future work in the field of AutoML.
The findings contribute to the ongoing efforts to develop robust and efficient AutoML frameworks, paving the way for advancements in automating machine learning processes and reducing the dependence on human expertise.

Nguyen et al. investigated that most AutoML-based Bayesian optimization approaches convert the AutoML optimization problem into a Hyperparameter Optimization (HPO) problem, i.e., by modeling the choice of algorithms as an additional categorical hyperparameter.
They pointed out that using this approach algorithms and their local hyper-parameters are referred to at the same level, and this makes the initial sampling less robust.
In \cite{9660073}, they attempted to formulate the AutoML optimization problem as a Bayesian optimization problem instead of transferring it into a HPO problem.
They proposed a novel initial sampling approach to maximize the coverage of the AutoML search space to help Bayesian optimization construct a robust model.
They tested this approach on 2 independent scenarios of AutoML with 2 operators and 6 operators over 117 benchmark datasets.
Experimental results showed that the performance of Bayesian optimization was significantly improved by using the proposed sampling approach.

In \cite{Feurer2020}, Feurer et al. introduced a new AutoML approach, named PoSH (Portfolio Successive Halving) Auto-Sklearn, which enabled AutoML systems to work well on large datasets under rigid time limits by using a meta-learning technique and a bandit strategy for budget allocation.
They also studied how to let AutoML explore the design space and automatically select the best configuration by itself.
These changes combined give rise to the next generation of their original Auto-Sklearn framework, called Auto-Sklearn 2.0.
They verified the improvements of these additions in an extensive experimental study on 39 AutoML benchmark datasets and compared the results to other popular AutoML frameworks and Auto-Sklearn 1.0, showing that the relative error is reduced by up to a factor of 4.5, and yielding performance in 10 minutes that was better than what Auto-Sklearn 1.0 achieved within an hour.

In \cite{Zimmer2020}, Zimmer et al. presented Auto-PyTorch, a comprehensive framework that enables fully AutoDL by jointly optimizing network architecture, training pipelines, and hyperparameters.
Auto-PyTorch utilizes multi-fidelity optimization techniques along with portfolio construction for warm starting and ensembling of Deep Neural Networks (DNNs), achieving state-of-the-art performance on many tabular benchmarks.
One notable contribution of the study is the introduction of a new benchmark on learning curves for DNNs.
This benchmark provides a valuable evaluation criterion for assessing the effectiveness of AutoDL frameworks.
The authors conducted extensive experiments on typical AutoML benchmarks, demonstrating that Auto-PyTorch outperformed several state-of-the-art competitors in terms of performance.

In their work, the authors of \cite{9534091} conducted a benchmark study to evaluate the performance of eight popular open-source AutoML tools: Auto-Keras, Auto-PyTorch, Auto-Sklearn, AutoGluon, H2O AutoML, rminer, TPOT, and TransmogrifAI.
They also selected twelve widely used OpenML datasets to serve as benchmarks for different machine learning tasks, including regression, binary classification, and multi-class classification.
The study focused on comparing the predictive scores and computational effort of the AutoML tools.
The best predictive results achieved by these tools were compared with the best public results from OpenML.
The comparison revealed that the AutoML tools consistently achieved competitive results, outperforming the best models from OpenML in five of the datasets.
These findings highlight the potential of AutoML tools in fully automating the process of ML algorithm selection and tuning.

In the following, some studies with a focus on the utilization of AutoML for time series forecasting applications are presented.

In \cite{9564380}, a data augmentation method was presented to enhance the performance of neural networks in time series forecasting tasks, especially when limited data is available.
The proposed method, known as Augmented-Neural-Network, incorporated forecasts from statistical models to achieve competitive results on intermediate-length time series.
The study demonstrated that combining data augmentation with AutoML techniques like NAS can lead to the discovery of suitable neural architectures for specific time series.
By applying this approach, significant improvements in forecasting accuracy were observed on a COVID-19 dataset, with an improvement of approximately 20\% compared to neural networks that did not utilize augmented data.

\cite{su142215292} conducted experiments on time series forecasting using ML, DL, and AutoML techniques.
The datasets used in the experiments were quantitative data of the real prices of the currently most used cryptocurrencies.
The results showed that AutoML for time series is still in the development stage and needs more study to be the main solution to adopt since it was unable to outperform manually designed ML and DL models.

In recent years, there has been significant improvement in the efficiency of AutoDL systems.
However, there has been limited focus on AutoDL frameworks specifically designed for time series forecasting.
In \cite{Deng2022}, Deng et al. proposed an efficient approach to jointly optimize the neural architecture and hyperparameters of the entire data processing pipeline for time series forecasting.
Unlike traditional NAS search spaces, the authors designed a novel NAS space that encompasses various state-of-the-art architectures.
This enables efficient macro-search over different DL approaches specifically tailored for time series forecasting.
To efficiently explore this large configuration space, the researchers employed Bayesian optimization with multi-fidelity optimization techniques.
The study conducted empirical investigations on various forecasting datasets using different budget types, which enabled efficient multi-fidelity optimization.
Moreover, the proposed system, named Auto-PyTorch-TS, was compared against several established baselines.
The results demonstrated that Auto-PyTorch-TS significantly outperformed the baselines across multiple datasets, highlighting its effectiveness in time series forecasting tasks.


\section{Electricity demand forecasting}
\label{sec:demandsoa}
\vspace{0.2 cm}

In this section, the techniques for electricity demand forecasting are presented.
Most of the presented techniques are considered very simple nowadays and usually rely on large aggregated data, both on a high number of people considered (e.g., the consumption generated by an entire country) or on a very large temporal aggregation (up to 1 year aggregated data).
Our use case is limited to the customers of a small company, from 2 to 4 thousand customers, and it requires forecasts for a one-month time horizon on an hourly basis.

In \cite{singh2013overview}, a comprehensive review of electricity demand forecasting techniques was presented.
The authors categorized electricity demand forecasting into three main categories:
short-term forecasts (typically ranging from one hour to one week),
medium-term forecasts (typically ranging from a week to a year),
and long-term forecasts (exceeding a year).
Based on the studies reviewed, electricity demand forecasting techniques were classified into three major groups:
Traditional Forecasting techniques (such as regression methods, exponential smoothing, and iterative reweighted least-squares),
Modified Traditional Techniques (including adaptive demand forecasting, Auto-Regressive (AR), Auto-Regressive Moving Average (ARMA), ARIMA, and SVM),
and Soft Computing Techniques (such as Genetic Algorithms (GAs), fuzzy logic, neural networks, and knowledge-based expert systems).
From the work, it can be inferred that demand forecasting techniques based on soft computing methods were gaining significant advantages thanks to their effectiveness.
Moreover, there was a clear trend towards hybrid methods that combine two or more of these techniques to enhance forecasting accuracy and performance.

\cite{TAYLOR200357} investigated the use of weather ensemble predictions in electricity demand forecasting for a period ranging from 1 to 10 days ahead.
They proposed a weather ensemble prediction by considering 51 scenarios for a weather variable.
For each scenario, they produced a scenario for the weather-related component of electricity demand.
The results showed that the average of the demand scenarios is a more accurate demand forecast than that produced using traditional weather forecasts.
The mean of the 51 scenarios is mathematically equivalent to taking the expectation over the weather-related component of the demand probability density function.
They also used the distribution of the demand scenarios to estimate the demand forecast uncertainty.

In \cite{MIRASGEDIS2006208}, Mirasgedis et al. focused on incorporating weather data into models for mid-term electricity demand forecasting.
They studied the daily and monthly electricity demand.
They observed that the monthly model outperformed the daily model thanks to its higher level of aggregation.
However, they also noted that the influence of weather on electricity demand is less effectively captured at a more granular level, as aggregated models may not fully account for the impact of unusual or extreme weather conditions on electricity consumption.
Through their analysis, the authors identified several key weather parameters that significantly affect electricity consumption in the Greek interconnected power system.
These parameters include the temperature of the day being forecasted, the temperature of the two preceding days, and the relative humidity.
These variables were found to be the most important factors in determining electricity demand variations.
By incorporating weather data into their models, Mirasgedis et al. aimed to improve the accuracy of mid-term electricity demand forecasts, considering the influence of weather conditions on electricity consumption patterns.

\cite{5686767} proposed a first use of a neural network with the backpropagation learning algorithm for Lao state yearly electricity demand forecasting.
They compared it with a regression analysis model showing the higher effectiveness and the great potential of neural networks in this task.

\cite{5518553} proposed two models for short-term Singapore electricity demand forecasting: the multiplicative decomposition model and the Seasonal ARIMA (SARIMA) model.
Results showed that both models can accurately predict the short-term Singapore demand and that the Multiplicative decomposition model slightly outperformed the SARIMA model.

In \cite{8093428}, an empirical study was conducted to develop electricity demand forecasting models using publicly available data and three ML models.
The study aimed to compare the performance of these models using different evaluation metrics.
The data was composed of several measurements of the electricity market in Turkey from 2011 to 2016 and was available for different time granularities (from hourly to yearly aggregated).
According to the best result in terms of MAPE, electricity demand was predicted with a 1.4\% error using the Random Forest model.
Overall, the study demonstrated the effectiveness of machine learning techniques, particularly the Random Forest model, in accurately predicting electricity demand.

In \cite{ALMUSAYLH20181}, Al-Musaylh et al. conducted a study on short-term electricity demand forecasting using MARS (Multivariate Adaptive Regression Spline), SVR, and ARIMA models.
The study utilized aggregated demand data from Queensland, Australia.
The findings indicated that the MARS and SVR models were more suitable for short-term electricity demand forecasting compared to the ARIMA model.
The ARIMA model, with its linear formulation, exhibited poorer performance across all forecasting horizons, resulting in high forecast errors.
The study highlighted that the MARS models offered a powerful and efficient forecasting framework.
These models demonstrated a balance between complexity and accuracy, outperforming the SVR models, suggesting that MARS can be considered an effective approach for short-term electricity demand forecasting.

In \cite{MA20193433}, the authors proposed a method for forecasting building energy consumption in some provinces of southern China using Support Vector Regression (SVR).
The aim of the study was to enhance the reliability of SVR in predicting building energy consumption.
To achieve this, the method incorporated multiple parameters as inputs, including weather data such as the yearly mean outdoor dry-bulb temperature, relative humidity, and global solar radiation.
Additionally, economic factors such as the ratio of urbanization, gross domestic product, household consumption level, and total area of the structure were considered.
By including these diverse parameters as inputs to the SVR model, the study demonstrated the presence of improvements in the accuracy and reliability of building energy consumption forecasts.

In \cite{8404313}, a RNN-based approach for forecasting Turkish electricity load was proposed.
The study utilized different types of RNN architectures, including LSTM networks and GRU networks.
The resulting 0.71\% MAPE of their approach achieved better results than existing methods based on ARIMA and ANNs on Turkish electricity load forecasting which achieved 2.6\% and 1.8\% MAPE respectively.
The findings suggest that the RNN-based approaches provide superior accuracy in predicting electricity load compared to traditional methods like ARIMA and ANNs.

In \cite{DU2018533} a novel hybrid forecasting system was successfully developed.
It was composed of four modules: data preprocessing module, optimization module, forecasting module, and evaluation module.
In the data preprocessing module, a signal processing approach was employed to decompose, reconstruct, identify, and mine the primary characteristics of the electrical power system time series.
Optimization algorithms were employed to optimize the parameters of these individual models in the optimization and forecasting modules.
Experimental results showed that the hybrid system can be able to satisfactorily approximate the actual value of the electrical power system time series.
This is an interesting study from which to take inspiration for the system modeling structure, which can be intended for general-purpose and not just for the electrical power use case.

\cite{KIM2019328} proposed a novel model called recurrent inception CNN (RICNN) that combines RNN and 1-dimensional CNN (1-D CNN).
The RICNN model utilizes a 1-D convolution inception module to calibrate the prediction time and the hidden state vector values obtained from nearby time steps.
This module optimizes the network by incorporating the prediction time generated by the RNN and the nearby hidden state vectors.
To evaluate the effectiveness of the RICNN model, the authors conducted experiments using power usage data from three large distribution complexes in South Korea.
The results showed that the RICNN model outperformed benchmark models such as MLP, RNN, and 1-D CNN in daily electric load forecasting, specifically for 48-time steps with a 30-minute interval.
The findings suggest that the RICNN model might be suitable for our specific use case.
However, its effectiveness on a wider time horizon would require further investigation.

In \cite{BEDI20191312}, Bedi and Toshniwal introduced a DL-based framework, called D-FED, to address the challenge of forecasting electricity demand while capturing long-term historical dependencies.
Existing methods typically focused on short-term dependencies and failed to consider long-term patterns.
The D-FED approach utilizes a LSTM network combined with a moving window-based multi-input multi-output mapping approach of active learning.
The study applied the D-FED framework to the electricity consumption data of Union Territory Chandigarh in India.
To evaluate its performance, the predictions generated by the D-FED model were compared with those of other models, including ANN, RNN, and SVR.
By employing the D-FED framework, the authors demonstrate improved forecasting accuracy compared to the other models examined.

In \cite{MUZAFFAR20192922}, Muzaffar and Afshari focused on electricity load forecasting by incorporating exogenous variables such as temperature, humidity, and wind speed.
They employed a LSTM network to model the load data and its dependencies on these external factors.
The study demonstrated that LSTM outperformed the other traditional methods such as ARMA, SARIMA, and ARMA with exogenous inputs (ARMAX) reducing the percentage of errors in forecasting the load time series.
One notable advantage of LSTM highlighted in the study is its ability to learn and capture seasonality patterns and trends from the data, without the need for explicitly extracting these features beforehand.
This capability of LSTM contributes to its improved forecasting accuracy compared to traditional methods.

In \cite{WEN2020106073}, Wen et al. presented a DL model for forecasting the load demand of aggregated residential buildings at an hourly resolution, taking into account the complexity and variability of the load.
The study utilized hourly-measured residential load data from Austin, Texas, to evaluate the effectiveness of the proposed model.
The forecasting error was quantitatively assessed using various metrics.
The proposed model, called DRNN-GRU, was employed in the study.
This model incorporates GRU within a deep RNN architecture.
Notably, the model assumes access to future weather data to make accurate forecasts.
However, it is important to consider that weather conditions can introduce uncertainty, especially over short to medium-term periods.
The results demonstrated that the proposed DRNN-GRU model achieved higher accuracy in forecasting both the aggregated and disaggregated load demand of residential buildings compared to conventional methods.
The study highlighted the improved performance of the DL model in capturing the complexities and variabilities inherent in residential load demand.

\cite{CHITALIA2020115410} presented a robust framework for short-term electrical load forecasting that is capable of capturing variations in building operation, irrespective of building type and location.
The researchers explored nine different hybrids of RNNs and clustering techniques.
The framework was tested on five commercial buildings representing different types: academic, research laboratory, office, school, and grocery store.
The load forecasting results demonstrated that the DL algorithms implemented in the study achieved a 20-45\% improvement in load forecasting performance compared to the current state-of-the-art methods for both hour-ahead and 24-ahead load forecasting.
Several important findings emerged from the study.
Firstly, the use of hybrid DL algorithms required as little as one month of data to deliver satisfactory hour-ahead load prediction.
Secondly, when 15-minute resolution data was available, it led to a 30\% improvement in hour-ahead load forecasting accuracy.
Lastly, the formulated methods were found to be robust against weather forecasting errors, indicating that they can effectively handle uncertainties associated with weather predictions.
The study provides valuable insights regarding the quantity and granularity of data required for accurate short-term load prediction within the specified time range.
However, it should be noted that these findings may not necessarily generalize to longer prediction ranges beyond the scope of the study.

In \cite{WANG2020117197}, Wang et al. proposed a novel approach for predicting periodic energy consumption using a LSTM network.
The authors highlighted that the approach was unique because most general forecasting methods did not explicitly consider the periodic nature of energy consumption.
The proposed method leverages the autocorrelation graph of real industrial data to extract hidden features.
Experiments were conducted using a cooling system, specifically focusing on one-step-ahead forecasting.
The performance of the LSTM model was compared against several traditional forecasting methods, including the ARMA model, the Auto-Regressive Fractional Integrated Moving Average (ARFIMA) model, and the backpropagation neural network (BPNN).
The results showed that the LSTM model outperformed the traditional methods in terms of Root Mean Square Error (RMSE).
Specifically, the RMSE of the LSTM model was found to be 19.7\%, 54.85\%, and 64.59\% lower than that of the BPNN, ARMA, and ARFIMA models, respectively, on the test data.
Additionally, the authors demonstrated that the proposed algorithm exhibited the highest generalization capability among the tested models.

In \cite{WANG2020114561}, Wang et al. proposed a stacking model for electricity load forecasting that combines the strengths of various basic prediction algorithms.
The goal of the stacking model is to leverage different perspectives and approaches to improve the accuracy and generalization of the final prediction model.
The study utilized load data obtained from two educational buildings located in Tianjin, China.
These buildings consisted of classrooms for students and offices for university staff.
The dataset was used as a case study to evaluate the performance of the proposed stacking model.
Experimental results showed that the stacking method outperformed other tested machine learning models, including Random Forest, GBDT, Extreme Gradient Boosting (XGBoost), SVM, and KNN.
The stacking model exhibited superior accuracy, generalization, and robustness in comparison to these alternative models.

In \cite{SOMU2021110591}, Somu et al. introduced a deep learning framework called kCNN-LSTM for accurate building energy consumption forecasting.
The framework incorporates three key components for leveraging the energy consumption data:
\begin{enumerate}
  \item k-means clustering, this component performs cluster analysis on the energy consumption data to identify patterns and trends;
  \item CNN, this component is used to extract complex features from the energy consumption data. It captures non-linear interactions and dependencies that influence energy consumption;
  \item LSTM network, this component is responsible for handling long-term dependencies in the time series data.
\end{enumerate}
The performance of the kCNN-LSTM model was evaluated by comparing it with the k-means variant of state-of-the-art energy demand forecast models.
Evaluation metrics such as Mean Square Error (MSE), RMSE, Mean Absolute Error (MAE), and MAPE were used to assess the accuracy of the energy consumption demand forecasts.
The experimental results demonstrated that the kCNN-LSTM model outperformed other models providing more accurate energy consumption demand forecasts.

In \cite{10033079}, a TFT model was proposed to forecast short-term loads.
The TFT included a sequence-to-sequence model, which processes the historical and future covariates to enhance the forecasting performance.
A Gated Residual Network (GRN) is applied to drop out unnecessary information and improve the efficiency of the model.
The proposed method is tested on anonymized data from a university campus with a time resolution of 30 minutes.
The anomalies and missing data (around 8.85\% of the total data) are imputed with the KNN imputation method.
The testing results demonstrate the effectiveness of the proposed method achieving a MAPE of less than 5\%.
Overall, the study presents an interesting work on a TFT model, which should be extended to obtain great performance also with higher prediction horizons in order to be applicable to the specific use case treated in this thesis.

\cite{LI2023108743} proposed an improved version of the TFT model, called ITFT, aiming to enhance the accuracy and comprehensiveness of forecasts for hourly load time series.
The approach involved reconstructing the hourly load data into multiple day-to-day load time series at different hours.
To improve the model's efficiency in capturing long-term dependencies, the ITFT model replaced the LSTM component with a GRU.
Additionally, the authors incorporated quantile constraints and prediction interval penalty terms into the original quantile loss function to prevent quantile crossover and generate more compact prediction intervals.
The study demonstrated that the proposed ITFT method provided a comprehensive explanation and substantially enhanced the reliability and compactness of probabilistic load forecasting compared to other widely used methods such as Quantile Regression Neural Network (QRNN) and Temporal Convolutional Network (TCN).


\section{Consumption baseline forecasting}
\label{sec:baselinesoa}
\vspace{0.2 cm}

In this section, the techniques for consumption baseline forecasting are presented.
As demonstrated by most of the following papers analyzed, computing forecasts for a single customer is a more complicated use case compared to energy demand forecast over a customer base.
Single customer data is more noisy and very few works consider a single habitation as the source of data in their studies, most of them consider commercial buildings, offices, or schools which present data with a reduced level of noise.

The S3C EU research project developed and tested different guidelines and tools, of particular interest for this use case is the guideline on how to create a consumption baseline\footnote{ \url{https://www.smartgrid-engagement-toolkit.eu/fileadmin/s3ctoolkit/user/guidelines/GUIDELINE_HOW_TO_CREATE_A_CONSUMPTION_BASELINE.pdf} }.
In particular, they defined the baseline as the reference used to assess the effects of the demand response of a given consumer or set of consumers.
The demand response effect is defined as the difference between the metered consumption and the baseline calculation.
They explained that the baseline calculation method consists of three criteria:
i) data selection method,
ii) estimation method,
and iii) result adjustment.
They pointed out that the combination of these criteria depends on user consumption, weather dependency (including seasonal behavior), and load behavior and should all together fit the user consumption pattern.

In \cite{DEB2017902}, Deb et al. compared multiple time series forecasting techniques for building energy consumption.
The evaluated methods included ANN, ARIMA, SVM, Case-Based Reasoning (CBR), Fuzzy time series, Grey prediction model, Moving average and exponential smoothing (MA \& ES), and KNN prediction method.
The researchers also examined hybrid models, which involve combining two or more forecasting techniques.
They found that the hybrid models exhibited the highest effectiveness in time series energy forecasting for individual buildings.

\cite{AMBER2018886} aimed to compare the prediction capabilities of five different intelligent system techniques in forecasting the electricity consumption of an administration building.
These five techniques were Multiple Regression (MR), Genetic Programming (GP), ANN, DNN, and SVM.
The prediction models were developed based on five years of observed data and additional parameters such as solar radiation, temperature, wind speed, humidity, and weekday index.
The weekday index was demonstrated as an important parameter that made it possible to differentiate between working and non-working days.
Experimental results suggested that ANN performed better than all other four techniques with a MAPE of 6\% whereas MR, GP, SVM, and DNN had a MAPE of 8.5\%, 8.7\%, 9\%, and 11\%, respectively.

\cite{FAN2019700} investigated the performance of different strategies for multi-step ahead building energy predictions.
The results of the study showed the potential of recurrent models in short-term building energy forecasting.
This study provided useful references for developing advanced DL models for practical applications.

In \cite{LUSIS2017654}, Lusis et al. investigated the impact of calendar effects, forecasting granularity, and the length of the training set on the accuracy of day-ahead load forecasts for residential customers.
The study compared the performance of regression trees, neural networks, and SVR techniques.
The results showed that regression trees, neural networks, and SVR produced similar average RMSE values.
However, statistical analysis revealed that the regression trees technique was significantly superior in terms of accuracy.
The inclusion of historical load profiles with daily and weekly seasonality, along with weather data, reduced the importance of explicit calendar effects in the load forecast.
The study also found that using one year of historical data was sufficient to develop an effective load forecast model for residential customers.
Further expansion of the training dataset did not yield significant improvements in forecast accuracy.
Additionally, the study demonstrated that forecast errors could be reduced by employing a coarser forecast granularity.
That is expected since aggregating data over longer time intervals, such as daily forecasts instead of hourly forecasts, reduces data variability and improves the quality of the results.

In \cite{PLATON201510}, Platon et al. developed predictive models by using ANN and CBR for producing hourly electricity consumption forecasts for a building.
CRB is based on the concept that the current trend of the building's electrical use can be approximated using past trends occurring at similar conditions.
The experimental results of the study indicated that ANN outperformed CBR in electricity consumption forecasting.
This finding suggests that CBR alone is not sufficient for accurate and reliable electricity consumption predictions.
The superiority of ANN over CBR highlights the importance of using more advanced techniques like ANN to achieve better forecasting performance in this context.

In \cite{7576207}, Jie et al. proposed a baseline load forecasting and optimization method based on non-demand-response factors, considering the effects of non-demand-response factors on customer load characteristics and customer baseline load (CBL) forecasting.
The proposed method combines non-demand-response factors mining, similar days selecting, and CBL calculating.
A combined calculation model is adopted to predict the CBL.
The case study reveals the greater accuracy of this method compared to average, linear regression, and neural network methods.

Forecast at the household level is also getting more and more popular in smart building control and demand response programs.
This popularity inspired Dong et al. to develop in \cite{DONG2016341} a hybrid model to address the problem of residential hour and day-ahead load forecasting through the integration of data-driven techniques with forward physics-based models.
They evaluated five different ML algorithms: ANN, SVR, least-square SVM (LS-SVM), Gaussian process regression (GPR), and Gaussian mixture model (GMM).
They applied these models to four residential data sets obtained from smart meters.
A subdivision of air conditioning (AC) consumption and not-AC was possible and this led to better results with respect to considering the total consumption.
The final results showed that the hybrid model led to improvements compared to the other ML algorithms for both hour-ahead and 24-h ahead predictions.

In \cite{MOCANU201691}, Mocanu et al. focused on two newly developed stochastic models, namely Conditional Restricted Boltzmann Machine (CRBM) and Factored Conditional Restricted Boltzmann Machine (FCRBM), for time series prediction of energy consumption.
The assessment of the two models was conducted on a benchmark dataset comprising nearly four years of one-minute resolution electric power consumption data collected from an individual residential customer.
The authors compared the performance of CRBMs and FCRBMs with that of ANN.
The results showed that as the prediction horizon increased, FCRBMs and CRBMs demonstrated greater robustness, with their prediction errors typically being half that of ANN.
Additionally, the experiments revealed that all methods performed better when predicting the aggregated active power consumption, as opposed to predicting the demand of intermittent appliances (e.g., electric water heater) recorded from sub-meterings.

In \cite{ALOBAIDI2018997}, a robust ensemble model was proposed to forecast day-ahead mean daily electricity consumption on the household level.
The proposed ensemble learning strategy utilized a two-stage resampling plan, which generated diversity-controlled but random resamples that were used to train individual ANN members.
Experimental results on a case study showed that the proposed ensemble was able to generate better forecasts compared to ANN models and the Bagging ensemble.

To counter the high nonlinearity between inputs and outputs of building energy consumption prediction models, in \cite{ZHONG2019403} a novel vector field-based SVR method was proposed.
The proposed method utilized multi-distortions applied to the sample data space or high-dimensional feature space, which was mapped by a vector field.
By exploring these distortions, the optimal feature space was identified, where the high nonlinearity between inputs and outputs can be effectively approximated by linearity.
To evaluate the effectiveness of the method, a large office building located in a coastal town in China was selected as a case study.
The summer hourly cooling load data of the building were used as the energy consumption data for the analysis.
The experimental results demonstrated that the proposed vector field-based SVR method achieved high accuracy, generalization ability, and robustness in predicting building energy consumption.
By effectively addressing the nonlinearity between inputs and outputs, the method provided a reliable approach for accurate and robust energy consumption prediction in buildings.

In \cite{SHAO2020102128}, Shao et al. studied and analyzed the energy consumption of hotel buildings by developing a SVM model.
The SVM model took as input variables the weather parameters and operating parameters of the hotel air-conditioning system.
They selected as the kernel function the RBF (Radial Basis Function) kernel function and optimized the parameters of the kernel for finding the best accuracy for the model predictions.
The R\textsuperscript{2} (coefficient of determination) of the final model prediction in the case study was 0.94.
This use case is different from the standard single-building forecasts since a hotel includes different rooms and aggregates the consumption over them, then it is more influenced by periods of the year where there could be more or fewer customers that require different levels of demand.
Moreover, in this case, hotel parameters like the air conditioning system are available and help in reducing the overall forecast error.

\cite{WANG201910} introduced a probabilistic load forecasting method designed to address the variability and uncertainty associated with future load profiles for individual consumers.
The proposed method utilizes a Pinball loss-guided LSTM network, which is capable of capturing both long-term and short-term dependencies within the load profiles.
The performance of the proposed method is evaluated on load forecasting tasks for both residential and commercial consumers.
Comparative experiments are conducted, comparing the proposed method against traditional forecasting methods such as QRNN, GBDT, and traditional LSTM.
The experimental results across different customers demonstrate that the proposed method outperforms the traditional methods in terms of forecasting accuracy and uncertainty estimation.

\cite{CAI20191078} aimed to use DL-based techniques for day-ahead multi-step load forecasting in commercial buildings.
The authors proposed and formulated RNN and CNN models in both recursive and direct multi-step manners.
To evaluate the performance of the DL models, they were compared with the SARIMA model with exogenous inputs (SARIMAX), which is a traditional forecasting method commonly used in this context.
Among the DL models tested, the gated 24-hour CNN model, implemented in a direct multi-step manner, achieved the best performance.
It significantly improved the forecasting accuracy by 22.6\% compared to the SARIMAX model.
This demonstrated the superiority of DL models in day-ahead multi-step load forecasting for commercial buildings.

In \cite{KIM201972}, Kim and Cho proposed a CNN-LSTM neural network architecture for predicting housing energy consumption.
This architecture combines the strengths of CNNs and LSTM networks to effectively extract spatial and temporal features.
The CNN layer in the proposed architecture is capable of capturing the relationships between various variables that influence energy consumption.
It extracts relevant features by considering the spatial context of these variables.
On the other hand, the LSTM layer captures the temporal dynamics and irregular trends present in the time series data.
This combination allows the model to capture both the spatial and temporal aspects of housing energy consumption.
The CNN-LSTM method demonstrated excellent prediction performance for housing energy consumption, outperforming conventional forecasting methods.
It achieved the lowest RMSE compared to other methods when applied to the dataset on individual household power consumption.
The model was able to effectively predict complex patterns of electric energy consumption at different time resolutions, including minute, hour, day, and week intervals.
It consistently outperformed other methods in all these cases.
The authors also mentioned that incorporating household characteristics such as occupancy and resident behavior could potentially have a significant impact on predicting electric energy consumption.
Considering these factors could further improve the performance of the model and enhance its accuracy in predicting energy consumption for individual households.

In \cite{SOMU2020114131}, Somu et al. introduced a hybrid model, called eDemand, for accurate and robust building energy consumption forecasting.
The proposed model combines LSTM networks with an improved sine cosine optimization algorithm.
To validate the effectiveness of the model, the authors collected live energy consumption data from an academic building, specifically the Indian Institute of Technology in Bombay.
The data was utilized to forecast energy consumption over short-term, mid-term, and long-term intervals.
The experimental results demonstrated that the eDemand model surpassed the performance of existing energy consumption forecast models, as evaluated using various metrics.
The proposed model exhibited superior accuracy and robustness in predicting building energy consumption.

In \cite{LIU2020109675}, the application of Deep Reinforcement Learning (DRL) techniques for forecasting building energy consumption was investigated.
This area has received limited attention in the literature.
The study focused on an office building and investigated three commonly-used DRL techniques: Asynchronous Advantage Actor-Critic (A3C), Deep Deterministic Policy Gradient (DDPG), and Recurrent Deterministic Policy Gradient (RDPG).
The objective of the study was to assess the potential of DRL techniques in building energy consumption prediction and compare their performance against commonly-used supervised models.
The authors conducted comprehensive experiments and evaluations to evaluate the effectiveness of the proposed DRL models.
The experimental results revealed that DDPG outperformed the supervised models in both single-step ahead prediction and multi-step ahead prediction tasks.
It demonstrated superior accuracy and performance compared to the other techniques.
On the other hand, while the RDPG model did not exhibit advantages over DDPG in single-step ahead prediction, it showed notable improvements in accuracy for multi-step ahead prediction.
In contrast, the A3C technique performed poorly in both single-step ahead and multi-step ahead prediction tasks, suggesting its inadequacy for forecasting building energy consumption.

Developing individual models for each customer is not a scalable solution due to its high computational complexity.
Instead, an ideal approach for an energy company would be to employ a model that utilizes customer-specific information as features and can generalize across the entire customer base.
Recent research efforts have been focusing on exploring innovative and advanced techniques to adopt this approach.
In the following are reported a few recent works that adopt this approach.

A novel deep ensemble learning-based probabilistic load forecasting framework is proposed in \cite{YANG2019116324} to quantify the load uncertainties of individual customers.
The presented framework employed the profiles of different customer groups and integrated them into the understanding of the task.
Specifically, customers were clustered into separate groups based on their profiles and a multitask representation learning approach was employed on these groups simultaneously.
This technique led to better feature learning across groups and it was particularly useful to improve the performance of predicting residential demand response and managing home energy in smart grids.
However, this technique in order to be applicable needs customers' personal information and a large customer base to be effective.

\cite{ZANG2021120682} introduced a novel approach for day-ahead residential load forecasting.
The method involved feature engineering, pooling, and a hybrid DL model.
The feature engineering process comprised two-stage preprocessing, which included decomposition and multi-source input dimension reconstruction of the data from each user.
Subsequently, a pooling operation was applied to merge the data from the target user and its interconnected users based on mutual information in descending order.
Lastly, a hybrid model with two input channels was developed by combining a LSTM network with a self-attention mechanism.
The evaluation was conducted on a dataset consisting of multiple residential users.
The proposed load forecasting method demonstrated the best performance when using a four-user data pool, 49 time steps, and 24 feature dimensions.
The achieved performance measures were 15.33\% for MAPE, 56.86 kW for MAE, and 82.50 kW for RMSE.
The results showcased that the proposed method is an effective choice for day-ahead residential load forecasting.

\cite{NAZIR2023100888} introduced a daily, weekly, and monthly energy consumption prediction model for individual customers using a TFT approach.
The study employed a TFT model that incorporated both primary and valuable data sources, along with batch training techniques.
The dataset consisted of 169 customers, but the TFT model was specifically tested on data from a single customer to showcase the effectiveness of the customer-based predictive model.
The performance of the proposed TFT model was compared to LSTM, interpretable LSTM, and TCN models.
The overall symmetric MAPE (sMAPE) values for LSTM, interpretable LSTM, TCN, and the proposed TFT model were found to be 29.78\%, 31.10\%, 36.42\%, and 26.46\% respectively.
The sMAPE results indicated that the TFT model outperformed the other DL models, demonstrating its superior performance.
This recent work highlights the intelligent use of time series data from different customers, which improves the forecast quality compared to other models when predicting energy consumption for a single customer.


\section{Electricity production forecasting}
\label{sec:productionsoa}
\vspace{0.2 cm}

Electricity production forecasting is a classic problem in the time series field.
In particular, recently the importance of renewable energy sources has been raised due to the clear effects of climate change.
Understanding how much energy the systems based on renewable energy sources can produce with respect to their maximum production capacity is crucial.
However, this is quite difficult to forecast since it depends on future natural phenomena.
Different studies in the literature distinguish between different renewable energy sources, such as photovoltaic (PV), wind, geothermal, biomass, and hydropower.
In this section, the techniques for PV electricity production forecasting are presented.

PVGIS\footnote{ \url{https://joint-research-centre.ec.europa.eu/pvgis-online-tool_en} } is a tool developed by the EU-Joint Research Center that provides information on solar radiation and the performance of PV plants across various locations in Europe, Africa, and large parts of Asia and America.
PVGIS uses reliable solar radiation data obtained from satellite images, along with climate reanalysis models providing ambient temperature and wind speed information.
It is a free tool that allows specifying the details of a PV plant to obtain its potential generation.
It is freely accessible and allows users to input specific details about a PV plant to estimate its potential energy generation.
While PVGIS is a useful resource for obtaining an indication of the potential energy generation of a PV plant, it may not provide the same level of accuracy as the methods described in scientific literature.
These specific methods often take into account historical data to derive site-specific production performance and consider up-to-date weather forecasts.
By focusing on individual plants and incorporating more detailed information, these methods can offer more accurate predictions of energy generation.

\cite{INMAN2013535} reviewed the theory behind the forecasting methodologies, and presented several successful applications of solar forecasting methods for both the solar resource and the power output of solar plants at the utility-scale level.
Some examples of the presented approaches are Regressive methods, ANNs, Numerical Weather Prediction (NWP), and hybrid methods incorporating two or more techniques.

In 2014, Zamo et al. presented a pair of articles proposing a benchmark study on statistical regression methods for short-term forecasting of PV electricity production.
The first one treated deterministic forecasts of hourly production \cite{ZAMO2014792}, and the second one probabilistic forecasts of daily production \cite{ZAMO2014804}.
The proposed benchmark designated Random Forest as the best forecast model for hourly PV production with a short lead time (from 28 to 45 h).
Their results also suggested that the RMSE can be reduced to about 5.8\% by first forecasting the production for each individual power plant and then summing these forecasts up.
For probabilistic forecasts of 2 days ahead daily production, quantile regression (QR) based forecasts performed significantly better than the climatology, with a CRPS (continuous ranked probability score) lowered by up to 50\%.
For most power plants, a QR-based forecast performs better than the other models.
But the most accurate forecast may vary from one power plant to another and with the number of forecast quantiles.

\cite{ANTONANZAS201678} presented a review of PV power forecasting techniques developed in the literature up to 2016.
The authors analyzed various methods including regressive methods, ANN, KNN, SVM, Random Forest, and hybrid methods.
The review highlighted the increasing use of ML techniques in recent papers due to their ability to model PV power generation without requiring detailed knowledge of plant characteristics.
ML models can learn these characteristics directly from the available data.
The study also discussed the spatial and temporal aspects of PV power forecasting.
The day-ahead horizon was found to be the most extensively researched, as it aligns with the planning and unit commitment activities in day-ahead energy markets.
Spatial averaging was identified as a useful technique in PV power forecasting.
It helps reduce the variability of solar resources and generates more reliable regional forecasts compared to single-site forecasts.
This is achieved through the smoothing effect, which mitigates errors with opposite signs across different PV plants.

Barbieri et al. in \cite{BARBIERI2017242} found out that ANNs and SVM are appropriate approaches for short-term horizons and NWP are better suited for longer horizons.
In fact, while a probabilistic method based on historical data may be valuable for very long-term forecasts, such an approach cannot take into consideration the complex variations of the cloud cover causing short-term sunlight disruptions.
Only a deterministic atmospheric modeling approach can deal with the stochastic changes of solar radiance during the day.
Within this type of model, NWP data-based models are well adapted for day-ahead forecasts but suffer from a too coarse temporal resolution.
Sky imagers are a precious tool to identify cloud types and anticipate the impact of shading on PV power generation.
They concluded by introducing some future works such as the elaboration of algorithms that can calculate cloud cover and classify clouds using online data and a fine sampling period.
In addition, measuring precisely the effects of each type of cloud on solar irradiance could greatly help in improving the results.

In \cite{DAS2018912}, Das et al. conducted a review of PV power forecasting models up to 2018.
They found that ANN and SVM models performed well in capturing the rapid and varying environmental conditions associated with PV power generation.
The researchers noted that many studies employed multiple techniques to enhance the accuracy of their forecasting models.
Furthermore, the review revealed that a significant number of studies classified forecasted days into different categories based on weather conditions.
This categorization allowed for the development of specific forecasting models tailored to each weather condition.
However, the observed error range in the reviewed studies was found to be notably high, which can be attributed to the diverse weather conditions that affect PV power generation.
To improve predictions and minimize errors, it is crucial for each sub-model developed for different weather conditions to perform well.

\cite{SOBRI2018459} classified solar PV forecasting methods into three main categories: time series statistical, physical, and ensemble methods.
Among the most used methods, ANN and SVM were present thanks to their ability to handle complex and non-linear forecasting models.
The evaluation of metrics demonstrated that Artificial Intelligence (AI) models, such as ANN and SVM, were able to reduce errors compared to other statistical approaches.
This highlights the effectiveness of AI techniques in improving the accuracy of solar PV forecasts.
Furthermore, ensemble methods, which combine linear and non-linear techniques, have emerged as a recent development in solar PV forecasting.
These ensemble methods have demonstrated enhanced accuracy and performance compared to individual models.
The study also discussed the standard metrics that are commonly used to evaluate the accuracy of solar PV predictions.
These metrics provide specific applications for assessing the performance of different solar forecasting approaches, enabling the selection of appropriate methods for achieving better performance in specific scenarios.

\cite{DEFREITASVISCONDI201954} presented a literature review on big data models for solar PV electricity generation forecasts, aiming to evaluate the most applicable and accurate state-of-the-art techniques to the problem.
They also included the motivation behind each project proposal, and the characteristics and quality of data used to address the problem, among other issues.
They affirmed that the prediction of solar electricity generation is currently an ongoing academic research question.
They noticed that ML was widely used, and approaches based on neural networks were considered the most accurate.
They concluded the study by emphasizing that the extreme learning machine (ELM) was also a great novelty and it presented reduced training time and raised precision.

In \cite{AHMAD2018465}, the accuracy, stability, and computational cost of Random Forest and Extra Trees techniques were investigated for predicting the hourly PV generation output.
The performance of these methods was compared with SVR.
The results of the study demonstrated that all the developed models had comparable predictive power and were equally applicable for predicting hourly PV output.
This suggests that both Random Forest and Extra Trees are effective techniques for PV generation forecasting.
However, in terms of computational cost, Extra Trees outperformed Random Forest and SVR.
The algorithmic efficiency and stability of Extra Trees made it a more efficient and practical choice for PV output forecasting.

In \cite{AHMED2020109792}, Ahmed et al. reviewed and evaluated contemporary PV solar power forecasting techniques.
The researchers observed that solar irradiance, among various features, exhibited the highest correlation with PV output.
Therefore, they emphasized the importance of weather classification and cloud motion study in achieving optimal forecasting results.
Regarding data preprocessing, they found that normalization and wavelet transforms were effective data-cleaning processes.
Additionally, they recommended the use of generative adversarial networks for data augmentation, which can improve the training and forecasting accuracy of models.
The optimization of inputs and network parameters was also discussed, and the researchers highlighted the utility of GAs and particle swarm optimization in this regard.
Based on their analysis, the researchers concluded that ensembles of ANNs were the most effective approach for short-term PV power forecasting.

\cite{9848724} examined the performance of the LSTM method in Turkey's electricity production estimation and determined the optimization technique that provides the best performance in the LSTM estimation method.
It was observed that the energy production estimation of LSTM combined with Adam optimization technique achieved the best results.

In \cite{GELLERT2019546}, Gellert et al. proposed and evaluated a context-based technique to anticipate electricity production and consumption in buildings.
They focused on a household with PVs and an energy storage system.
They analyze the efficiency of Markov chains, stride predictors\footnote{A stride predictor is a computational prediction method that relies on trends in the data. The next value is computed by adding the previous value to a stride value determined as the difference between the two most recent values.}, and also their combination into a hybrid predictor in modeling the evolution of electricity production and consumption.
Experimental results showed that the best predictor is the Markov chain configured with an electric power history of 100 values, a context of one electric power value, and an interval size of 1.

In \cite{VANDEVENTER2019367}, a GA-based SVM (GASVM) model was proposed for short-term power forecasting of residential-scale PV systems.
The GASVM model utilized historical weather data and employed an SVM classifier for initial classification.
Subsequently, a GA was applied to optimize the model using an ensemble technique.
Experimental results demonstrated that the GASVM model outperformed the conventional SVM model in terms of forecasting accuracy.
Specifically, the GASVM model achieved a significant improvement over the SVM model, with a difference of 669.624W in the RMSE value and 98.7648\% in the MAPE, compared to the SVM model's MAPE of 100.47\%.
The GASVM model achieved an impressive MAPE of 1.7052\%, indicating its superior performance in accurately predicting the power output of residential-scale PV systems.

In \cite{ZHOU2020117894}, a hybrid novel model called SDA-GA-ELM based on the combination of ELM, GA, and customized similar day analysis (SDA) was proposed for hourly PV power output prediction.
The SDA component utilized the Pearson correlation coefficient to measure the similarity between different days based on five meteorological factors.
Using this analysis, data samples similar to the target forecast day were selected as the training set for the ELM model.
The ELM component served as the prediction model and was optimized using the GA.
The GA was employed to search for optimal values of the ELM parameters, enhancing the accuracy of the PV power output prediction.
Experimental results demonstrated that the SDA-GA-ELM model outperformed other tested approaches, including ELM, SVM, SDA-ELM, and SVM-ELM, in day-ahead PV power prediction.
The SDA-GA-ELM model exhibited higher accuracy and stability, highlighting its effectiveness in accurately forecasting the hourly PV power output.

\cite{9248865} presented case studies on forecasting PV power production and electricity demand in Portugal.
They studied an ensemble of different methods, including SVM, Random Forest, LSTM, and ARIMA, to exploit the growing collection of energy supply and demand records.
The ensemble used only electricity data to forecast since only this data is available online for any forecasting horizon.
The ensemble method was based on offline training and online forecasting, by applying the most recent power measurements to trained models.
The different methods performed different non-linear transformations to the same electricity data, thus introducing diversity in the ensemble.
To assess the forecasting performance of the system, they considered two forecasting horizons relevant to the Internal Electricity Market, namely 36 hours ahead, relevant to the single day-ahead coupling, and 2 hours ahead, relevant to the single intraday coupling.
The forecasting performance using only electricity data is compared with state-of-the-art models and improves the reference accuracy in their case studies.
Since the ensemble relies only on energy data, the results showed that the proposed methods are useful to exploit energy big data for efficient energy forecasting systems.
As demonstrated by other papers, weather information such as solar irradiance has a high correlation with energy production, and when studying a few plants, instead of all the ones in Portugal, this information has a relevant impact on performance.

In \cite{WANG2017409}, a novel hybrid method for deterministic PV power forecasting was proposed, combining wavelet transform and CNN.
The wavelet transform was applied to decompose the original PV power signal into different frequency series, enabling the analysis of variations at different scales.
This decomposition using wavelet transform helped capture the inherent structures and patterns within the signal.
The CNN was then utilized to extract nonlinear features and invariant structures from each frequency series.
CNN is well-suited for capturing spatial and temporal patterns, making it suitable for analyzing the transformed PV power data.
Additionally, the study also developed a probabilistic PV power forecasting model by combining the proposed deterministic method with spine quantile regression. This probabilistic model enabled the statistical evaluation of the uncertainty and provided probabilistic information in PV power data.
The results of the study showed that the proposed deterministic model, based on wavelet transform and CNN, outperformed the compared benchmarks considering several error metrics in terms of various factors such as seasons, forecasting horizons, and PV power locations.

In \cite{GAO2019115838}, day-ahead power output time series forecasting methods were proposed, considering separately the case of ideal weather conditions (sunny days) and non-ideal weather conditions (rainy days, windy days, and foggy days).
For ideal weather conditions, the authors proposed a forecasting method based on meteorology data of the next day using LSTM.
For non-ideal weather conditions, the study took into account the time series relevance and specific characteristics of each non-ideal weather type by introducing adjacent day time series and typical weather type information into the LSTM model.
The daily total power, obtained using the discrete grey model, was used as an input variable to correct the power output time series prediction.
Comparisons between the proposed methods and traditional algorithms revealed that the forecasting methods based on LSTM networks achieved high accuracy.
For ideal weather conditions, the RMSE was 4.62\%.
For non-ideal weather conditions, the proposed methods effectively captured the dynamic characteristics, resulting in superior prediction accuracy compared to traditional algorithms.
While the study presents an interesting approach by treating the problem in two subcases, it acknowledges the need for a single network that can adapt to different weather conditions on its own.
Such an adaptable network would be more practical for real-world applications where weather conditions can vary, eliminating the need to distinguish between ideal and non-ideal weather types.

In \cite{WANG2019113315}, three different models, namely CNN, LSTM, and a hybrid model combining CNN and LSTM, were proposed and applied to the DKASC college PV system data for prediction purposes.
The results of the study indicated that increasing the length of the input sequence had a positive impact on the accuracy of the models.
As the input sequence length increases, the models are able to capture more temporal dependencies and patterns in the data, leading to improved prediction performance.
Among the three models tested, the hybrid model based on CNN and LSTM achieved the best prediction performance.
The CNN model also performed well in terms of prediction accuracy, although it did not leverage temporal dependencies as effectively as the LSTM.
On the other hand, the LSTM network, while having the worst prediction effect, offered the advantage of a shorter training time.

In \cite{WANG2019116225}, a hybrid DL model called LSTM-CNN was proposed for PV power prediction.
The LSTM-CNN model leveraged the strengths of both LSTM and CNN architectures to improve prediction accuracy.
The temporal features of the data were first extracted by the LSTM network, which is well-suited for capturing sequential dependencies in time series data.
Then, the spatial features of the data were extracted by the CNN model, which is effective in capturing spatial patterns in data.
By combining the temporal and spatial features, the hybrid LSTM-CNN model achieved better prediction performance compared to using the single prediction models separately.
The results indicated that the proposed hybrid model outperformed the CNN-LSTM model, where the spatial characteristics were extracted first and then the temporal characteristics.
Overall, the study highlights the benefits of integrating LSTM and CNN architectures in a hybrid DL model for PV power prediction, resulting in improved prediction accuracy by leveraging both temporal and spatial information in the data.

In \cite{LI2020114216}, a hybrid DL model combining wavelet packet decomposition and LSTM networks was proposed for one-hour-ahead PV power forecasting with five-minute intervals.
The wavelet packet decomposition technique was initially used to decompose the original PV power series into sub-series.
This decomposition helped capture different frequency components present in the data.
After the decomposition, four independent LSTM networks were developed, with each network responsible for predicting a specific sub-series.
Once the predictions from each LSTM network were obtained, the results were reconstructed and combined using a linear weighting method.
This finalized the forecasting results of the hybrid DL model.
The experimental results demonstrated that the proposed hybrid DL model outperformed other commonly used DL models, including LSTM, RNN, GRU, and MLP.
The hybrid model exhibited superior performance in terms of both forecasting accuracy and stability.

In \cite{MELLIT2021276}, various neural network models were developed and compared for short-term output PV power forecasting.
The neural networks investigated included LSTM, Bidirectional-LSTM (BiLSTM), GRU, Bidirectional-GRU (BiGRU), 1-D CNN, as well as hybrid configurations such as 1-D CNN-LSTM and 1-D CNN-GRU.
The researchers used a database of PV power generated by a microgrid at the University of Trieste in Italy to train and test the neural networks.
The performance evaluation was conducted over four different time horizons, considering both one-step ahead and multi-step ahead forecasting.
The results indicated that the investigated neural network models achieved high accuracy, particularly for the 1-minute time horizon with one-step ahead forecasting, where the correlation coefficient was close to 1.
For multi-step ahead forecasting (up to 8 steps ahead), the results were also found to be acceptable, with correlation coefficients ranging between 96.9\% and 98\%.
The advanced neural network algorithms demonstrated their capability to provide accurate predictions even on cloudy days, indicating their potential for handling challenging weather conditions.
However, it is important to note that the study primarily focuses on short-term forecasting and fine-time granularity.
The effectiveness of these models over longer time ranges should be further investigated.

In \cite{en15145232}, the TFT model was applied to predict hourly day-ahead PV power generation.
The proposed model was trained and tested using data from six different PV plants located in Germany and Australia.
The performance of the TFT model was compared with other algorithms including ARIMA, LSTM, MLP, and XGBoost.
The results of the study demonstrated that the use of the TFT model outperformed the other algorithms in terms of accuracy for forecasting PV generation in the tested plants.
This highlighted the effectiveness of the TFT model for this specific task.
Furthermore, the importance of the decoder and encoder variables in the TFT model was calculated.
The analysis revealed that solar horizontal irradiation and the zenith angle were the key variables for the model, indicating their significant influence on the accuracy of the predictions.
It is worth noting that while the TFT model proved to be more accurate, it is also more complex and requires a larger amount of data to achieve good prediction results compared to standard deep learning models.
